{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'  # 중복로드시 에러 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.16 (default, Mar  2 2023, 03:21:46) \n",
      "[GCC 11.2.0]\n",
      "현재 가상 환경 경로: /opt/anaconda3/envs/cuda11.8-pytorch2.0.0-py3.8\n",
      "/opt/anaconda3/envs/cuda11.8-pytorch2.0.0-py3.8/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(\"현재 가상 환경 경로:\", sys.prefix)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install albumentations\n",
    "# %pip install segmentation_models_pytorch\n",
    "# %pip install matplotlib\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install numpy\n",
    "# %pip install opencv-python\n",
    "# # (서버 환경이나 GUI가 필요없다면 opencv-python-headless를 사용할 수도 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cuda11.8-pytorch2.0.0-py3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/cuda11.8-pytorch2.0.0-py3.8/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import albumentations as albu\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.utils\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and Initialize File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_dir(target_path):\n",
    "    if os.path.exists(target_path):\n",
    "        shutil.rmtree(target_path)\n",
    "        os.makedirs(target_path)\n",
    "    else:\n",
    "        os.makedirs(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = os.getcwd()\n",
    "dataset_name = 'Full_Image'\n",
    "dataset_path=os.path.join(workspace_path, dataset_name)\n",
    "\n",
    "auto_labeling_path = os.path.join(dataset_path, 'cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG_images_name = []\n",
    "TG_labels_name = []\n",
    "\n",
    "for i in range(1, 15):\n",
    "    if i == 8:\n",
    "        pass\n",
    "    else:\n",
    "        TG_images_name.append(str(i)+'_TIFF_Cropped')\n",
    "        TG_labels_name.append(str(i)+'_JSON_Cropped')\n",
    "\n",
    "AKITA_images_name = []\n",
    "AKITA_labels_name = []\n",
    "\n",
    "for i in range(1, 7):\n",
    "    AKITA_images_name.append('AKITA.'+str(i)+'_TIFF_Cropped')\n",
    "    AKITA_labels_name.append('AKITA.'+str(i)+'_JSON_Cropped')\n",
    "\n",
    "STZ_images_name = []\n",
    "STZ_labels_name = []\n",
    "\n",
    "STZ_images_name.append('B6 STZ.01_TIFF_Cropped')\n",
    "STZ_labels_name.append('B6 STZ.01_JSON_Cropped')\n",
    "\n",
    "STZ_images_name.append('B6 STZ.02_TIFF_Cropped')\n",
    "STZ_labels_name.append('B6 STZ.02_JSON_Cropped')\n",
    "\n",
    "for i in range(1, 7):\n",
    "    if i == 5:\n",
    "        pass\n",
    "    else:\n",
    "        STZ_images_name.append('STZ.50mpk.0'+str(i)+'_TIFF_Cropped')\n",
    "        STZ_labels_name.append('STZ.50mpk.0'+str(i)+'_JSON_Cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG_imgs = []\n",
    "TG_labels = []\n",
    "for name in TG_images_name:\n",
    "    TG_imgs.append(os.path.join(auto_labeling_path,name))\n",
    "for name in TG_labels_name:\n",
    "    TG_labels.append(os.path.join(auto_labeling_path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKITA_imgs = []\n",
    "AKITA_labels = []\n",
    "for name in AKITA_images_name:\n",
    "    AKITA_imgs.append(os.path.join(auto_labeling_path,name))\n",
    "for name in AKITA_labels_name:\n",
    "    AKITA_labels.append(os.path.join(auto_labeling_path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "STZ_imgs = []\n",
    "STZ_labels = []\n",
    "for name in STZ_images_name:\n",
    "    STZ_imgs.append(os.path.join(auto_labeling_path,name))\n",
    "for name in STZ_labels_name:\n",
    "    STZ_labels.append(os.path.join(auto_labeling_path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604 1604\n",
      "357 357\n",
      "550 550\n"
     ]
    }
   ],
   "source": [
    "tg_img_cnt = 0\n",
    "tg_label_cnt = 0\n",
    "\n",
    "akita_img_cnt = 0\n",
    "akita_label_cnt = 0\n",
    "\n",
    "stz_img_cnt = 0\n",
    "stz_label_cnt = 0\n",
    "\n",
    "for i in range(len(TG_imgs)):\n",
    "    tg_img_cnt += len(os.listdir(TG_imgs[i]))\n",
    "    tg_label_cnt += len(os.listdir(TG_labels[i]))\n",
    "\n",
    "for i in range(len(AKITA_imgs)):\n",
    "    akita_img_cnt += len(os.listdir(AKITA_imgs[i]))\n",
    "    akita_label_cnt += len(os.listdir(AKITA_labels[i]))\n",
    "\n",
    "for i in range(len(STZ_imgs)):\n",
    "    stz_img_cnt += len(os.listdir(STZ_imgs[i]))\n",
    "    stz_label_cnt += len(os.listdir(STZ_labels[i]))\n",
    "\n",
    "print(tg_img_cnt, tg_label_cnt)\n",
    "print(akita_img_cnt, akita_label_cnt)\n",
    "print(stz_img_cnt, stz_label_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(dataset_path,'Autolabeling_dataset')\n",
    "\n",
    "x_dataset_dir = os.path.join(DATA_DIR, 'imgs')\n",
    "y_dataset_dir = os.path.join(DATA_DIR, 'labels')\n",
    "rebuild_dir(x_dataset_dir)\n",
    "rebuild_dir(y_dataset_dir)\n",
    "\n",
    "x_train_data_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_data_dir = os.path.join(DATA_DIR, 'train_labels')\n",
    "rebuild_dir(x_train_data_dir)\n",
    "rebuild_dir(y_train_data_dir)\n",
    "\n",
    "x_test_data_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_data_dir = os.path.join(DATA_DIR, 'test_labels')\n",
    "rebuild_dir(x_test_data_dir)\n",
    "rebuild_dir(y_test_data_dir)\n",
    "\n",
    "ckpt_path = os.path.join(DATA_DIR,'ckpt')\n",
    "if not os.path.exists(ckpt_path):\n",
    "    os.makedirs(ckpt_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 병합 및 이름 변경\n",
    "def merge_and_rename_files(src_dir, dst_dir, prefix):\n",
    "    for filename in os.listdir(src_dir):\n",
    "        src_file_path = os.path.join(src_dir, filename)\n",
    "        if os.path.isfile(src_file_path):\n",
    "            # 새로운 파일명 생성\n",
    "            new_filename = f\"{prefix}_{filename}\"\n",
    "            dst_file_path = os.path.join(dst_dir, new_filename)\n",
    "            # 파일 복사\n",
    "            shutil.copy2(src_file_path, dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TG_imgs)):\n",
    "    merge_and_rename_files(TG_imgs[i], x_dataset_dir, TG_images_name[i])\n",
    "    merge_and_rename_files(TG_labels[i], y_dataset_dir, TG_images_name[i])\n",
    "\n",
    "for i in range(len(AKITA_imgs)):\n",
    "    merge_and_rename_files(AKITA_imgs[i], x_dataset_dir, AKITA_images_name[i])\n",
    "    merge_and_rename_files(AKITA_labels[i], y_dataset_dir, AKITA_images_name[i])\n",
    "\n",
    "for i in range(len(STZ_imgs)):\n",
    "    merge_and_rename_files(STZ_imgs[i], x_dataset_dir, STZ_images_name[i])\n",
    "    merge_and_rename_files(STZ_labels[i], y_dataset_dir, STZ_images_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터수 : 2511\n",
      "훈련 데이터 수 = img :  2260 , label :  2260\n",
      "검증 데이터 수 = img :  251 , label :  251\n"
     ]
    }
   ],
   "source": [
    "def permutation_train_test_split(data,label , valid_size=0.2, shuffle=True, random_state=seed):\n",
    "    data_len=len(data)\n",
    "    print(f'전체 데이터수 : {data_len}')\n",
    "    valid_num=int(data_len*valid_size)\n",
    "    train_num=data_len-valid_num\n",
    "\n",
    "    if shuffle:\n",
    "        shuffled=np.random.permutation(data_len)\n",
    "        data=data[shuffled]\n",
    "        label=label[shuffled]\n",
    "        x_train=data[:train_num]\n",
    "        y_train=label[:train_num]\n",
    "        x_valid=data[train_num:]\n",
    "        y_valid=label[train_num:]\n",
    "    else:\n",
    "        x_train=data[:train_num]\n",
    "        y_train=label[:train_num]\n",
    "        x_valid=data[train_num:]\n",
    "        y_valid=label[train_num:]\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "# Train, Validation 파일 나누기 (8:2)\n",
    "X_path=np.array(glob.glob(x_dataset_dir+\"/*.png\"))\n",
    "Y_path=np.array(glob.glob(y_dataset_dir+\"/*.png\"))\n",
    "x_train, y_train, x_valid, y_valid=permutation_train_test_split(X_path,Y_path,valid_size=0.1,shuffle=True,random_state=seed)\n",
    "\n",
    "print('훈련 데이터 수 = img : ',len(x_train),', label : ',len(y_train))\n",
    "print('검증 데이터 수 = img : ',len(x_valid),', label : ',len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_train:\n",
    "    shutil.copy2(i,x_train_data_dir)\n",
    "for i in y_train:\n",
    "    shutil.copy2(i,y_train_data_dir)\n",
    "for i in x_valid:\n",
    "    shutil.copy2(i,x_test_data_dir)\n",
    "for i in y_valid:\n",
    "    shutil.copy2(i,y_test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    CLASSES = ['x' for x in range(255)]\n",
    "    CLASSES.append('cell')\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images_dir,\n",
    "            masks_dir,\n",
    "            classes=None,\n",
    "            augmentation=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = sorted(os.listdir(images_dir))\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "\n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=(0.3, 0.9), rotate_limit=90, p=0.2, border_mode=cv2.BORDER_REPLICATE),\n",
    "\n",
    "        albu.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                # albu.RandomBrightness(p=1),\n",
    "                # 오류 발생 원인: RandomBrightness → 수정 필요!\n",
    "                albu.RandomBrightnessContrast(p=1),  # ✅ 수정된 부분\n",
    "                \n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "                albu.GaussianBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                # albu.RandomBrightness(p=1),\n",
    "                albu.RandomBrightnessContrast(p=1),  # ✅ 수정된 부분\n",
    "                \n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "        albu.OneOf([\n",
    "            albu.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "            albu.ISONoise(p=1),\n",
    "        ], p=0.3),\n",
    "\n",
    "        # --- 항상 마지막에 크기 고정 ---\n",
    "        albu.Resize(512, 512, always_apply=True),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        # albu.PadIfNeeded(512, 512)\n",
    "        \n",
    "        albu.Resize(512, 512, always_apply=True),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define encoder, activation function, model, hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'efficientnet-b2'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['cell']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # DirectML 디바이스 생성\n",
    "# dml = torch_directml.device()\n",
    "# DEVICE = dml\n",
    "MODEL = 'Unet++'\n",
    "EPOCH = 30\n",
    "# create segmentation model with pretrained encoder\n",
    "if MODEL == 'Unet':\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "elif MODEL == 'Unet++':\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "elif MODEL == 'FPN':\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "else:\n",
    "    print('No model!')\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataloader (원본+증대 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners\n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "\n",
      "Epoch: 0\n",
      "train:  28%|██████████████████████████████████████▏                                                                                                | 120/424 [01:09<02:53,  1.75it/s, dice_loss - 0.8949, iou_score - 0.2245]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 8\n",
    "k_folds = 4\n",
    "\n",
    "train_logs_list, valid_logs_list = [], []\n",
    "max_score = 0\n",
    "\n",
    "original_dataset = Dataset(\n",
    "    x_train_data_dir,\n",
    "    y_train_data_dir,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "augmented_dataset = Dataset(\n",
    "    x_train_data_dir,\n",
    "    y_train_data_dir,\n",
    "    augmentation=get_training_augmentation(),  # 여기에 증대 적용\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(original_dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_original_subset = Subset(original_dataset, train_ids)\n",
    "    train_augmented_subset = Subset(augmented_dataset, train_ids)\n",
    "    valid_subset = Subset(original_dataset, valid_ids)\n",
    "\n",
    "     # 원본 데이터셋과 증대된 데이터셋을 합친 훈련 데이터셋\n",
    "    train_combined_subset = ConcatDataset([train_original_subset, train_augmented_subset])\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader = DataLoader(train_combined_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        print(f'\\nEpoch: {epoch}')\n",
    "\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader) \n",
    "        train_logs_list.append(train_logs)\n",
    "        valid_logs_list.append(valid_logs)\n",
    "\n",
    "        if max_score < valid_logs['iou_score']:\n",
    "            max_score = valid_logs['iou_score']\n",
    "            torch.save(model, os.path.join(ckpt_path,'{}_model.pth'.format(dataset_name)))\n",
    "            print('Model saved!')\n",
    "\n",
    "    print(f'Finished fold {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "print('Training and evaluation completed for all folds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load(os.path.join(ckpt_path,'{}_model.pth'.format(dataset_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = os.path.join(ckpt_path,dataset_name)\n",
    "sample_prediction = os.path.join(sample_path,'prediction')\n",
    "sample_compare = os.path.join(sample_path,'compare(original-label-img)')\n",
    "rebuild_dir(sample_path)\n",
    "rebuild_dir(sample_prediction)\n",
    "rebuild_dir(sample_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_vis = Dataset(\n",
    "    x_test_data_dir,\n",
    "    y_test_data_dir,\n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = Dataset(\n",
    "    x_test_data_dir,\n",
    "    y_test_data_dir,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)\n",
    "print(\"Evaluation on Test Data: \")\n",
    "print(f\"Mean IoU Score: {logs['iou_score']:.4f}\")\n",
    "print(f\"Mean Dice Loss: {logs['dice_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours_on_image(image, mask, color):\n",
    "    \"\"\"Mask의 테두리를 주어진 색상으로 이미지에 그립니다.\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, color, 2)\n",
    "    return image_with_contours\n",
    "\n",
    "def count_pixels_in_mask(mask):\n",
    "    \"\"\"마스크 안의 픽셀 수를 반환합니다.\"\"\"\n",
    "    return np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, len(test_dataset)):\n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image_vis = cv2.cvtColor(image_vis, cv2.COLOR_BGR2RGB)\n",
    "    image, gt_mask = test_dataset[n]\n",
    "\n",
    "    gt_mask = gt_mask.squeeze()\n",
    "\n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "\n",
    "    red_contoured = draw_contours_on_image(image_vis, (gt_mask * 255).astype(np.uint8), (255, 0, 0))\n",
    "    blue_contoured = draw_contours_on_image(image_vis, (pr_mask * 255).astype(np.uint8), (0, 0, 255))\n",
    "    combined_contoured = draw_contours_on_image(red_contoured, (pr_mask * 255).astype(np.uint8), (0, 0, 255))\n",
    "\n",
    "    red_pixels_count = count_pixels_in_mask(gt_mask)\n",
    "    blue_pixels_count = count_pixels_in_mask(pr_mask)\n",
    "    \n",
    "    intersection = np.logical_and(gt_mask, pr_mask)\n",
    "    union = np.logical_or(gt_mask, pr_mask)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 6, figsize=(21, 7), facecolor='white')\n",
    "\n",
    "    axes[0].set_title('original image', fontsize=10, pad=10)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].imshow(image_vis)\n",
    "\n",
    "    axes[1].set_title('Ground Truth', fontsize=10, pad=10)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].imshow(cv2.cvtColor(gt_mask, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "    axes[2].set_title('prediction', fontsize=10, pad=10)\n",
    "    axes[2].axis('off')\n",
    "    axes[2].imshow(cv2.cvtColor(pr_mask, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "    axes[3].set_title('label with red contours', fontsize=10, pad=10)\n",
    "    axes[3].axis('off')\n",
    "    axes[3].imshow(red_contoured)\n",
    "\n",
    "    axes[4].set_title('prediction with blue contours', fontsize=10, pad=10)\n",
    "    axes[4].axis('off')\n",
    "    axes[4].imshow(blue_contoured)\n",
    "\n",
    "    axes[5].set_title('combined contours on original', fontsize=10, pad=10)\n",
    "    axes[5].axis('off')\n",
    "    axes[5].imshow(combined_contoured)\n",
    "\n",
    "    # 각 subplot에 텍스트 추가\n",
    "    axes[3].text(10, 10, f'Red pixels: {red_pixels_count}', color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "    axes[4].text(10, 10, f'Blue pixels: {blue_pixels_count}', color='white', fontsize=12, bbox=dict(facecolor='blue', alpha=0.5))\n",
    "    axes[5].text(10, 10, f'IoU score: {iou_score:.4f}', color='white', fontsize=12, bbox=dict(facecolor='green', alpha=0.5))\n",
    "\n",
    "    plt.savefig(os.path.join(sample_compare, 'sample_compare_%05d.png' % n))\n",
    "    cv2.imwrite(os.path.join(sample_prediction, '%05d.png' % n), cv2.cvtColor(pr_mask, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show and save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_df = pd.DataFrame(train_logs_list)\n",
    "valid_logs_df = pd.DataFrame(valid_logs_list)\n",
    "train_logs_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=3, label = 'Train')\n",
    "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=3, label = 'Valid')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('IoU Score', fontsize=20)\n",
    "plt.title('IoU Score Plot', fontsize=20)\n",
    "\n",
    "# y축의 틱 간격을 0.1로 조절\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(sample_path,'iou_score_plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(), lw=3, label = 'Train')\n",
    "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(), lw=3, label = 'Valid')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Dice Loss', fontsize=20)\n",
    "plt.title('Dice Loss Plot', fontsize=20)\n",
    "\n",
    "# y축의 틱 간격을 0.1로 조절합니다.\n",
    "plt.yticks(np.arange(0, max(train_logs_df.dice_loss.max(), valid_logs_df.dice_loss.max()) + 0.1, 0.1))\n",
    "\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(sample_path,'dice_loss_plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} done'.format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_logs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_df.to_csv(os.path.join(sample_path,'train_{}_{}epoch.csv'.format(MODEL,EPOCH)))\n",
    "valid_logs_df.to_csv(os.path.join(sample_path,'valid_{}_{}epoch.csv'.format(MODEL,EPOCH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
