import cv2
import os
import torch
from torch.utils.data import DataLoader
from torch.utils.data import Dataset as BaseDataset

os.environ["NO_ALBUMENTATIONS_UPDATE"] = "1"
import albumentations as albu
import sys

import segmentation_models_pytorch as smp
import segmentation_models_pytorch.utils

import numpy as np
import pandas as pd 
from PIL import Image
import shutil
import glob

import random
from tqdm.auto import tqdm

import definition



if __name__ == "__main__":
    # sys.argv[1:]ë¡œ ìŠ¤í¬ë¦½íŠ¸ëª… ì´í›„ì˜ ì¸ìë§Œ ì¶”ì¶œ
    image_paths = sys.argv[1:]  # ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
    image_file = [x.split("\\")[-1] for x in image_paths]
    image_dir = image_paths[0].split("\\")[:-1]  # ì²« ë²ˆì§¸ ê²½ë¡œ ì‚¬ìš©

    current_path = os.path.dirname(os.path.abspath(__file__)) # main í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œ
    workspace_path = os.path.join(current_path, "model_train","model_load")
    dataset_name = 'Full_Image'
    dataset_path=os.path.join(workspace_path, dataset_name)
    ckpt_path = os.path.join(dataset_path,'Autolabeling_dataset','ckpt')
    
    sample_path = os.path.join(current_path,"result2")
    sample_crop = os.path.join(sample_path,'preprocessing','Crop')  # ìë¥¸ ì´ë¯¸ì§€
    sample_label = os.path.join(sample_path,'preprocessing','Label')  # ìë¥¸ ë¼ë²¨

    sample_prediction = os.path.join(sample_path,'prediction')  # ë§ˆìŠ¤í¬ ê²°ê³¼
    sample_imgs = os.path.join(sample_path,'imgs')  # ì›ë³¸ ì´ë¯¸ì§€

    
    # pd.set_option('display.max_colwidth', 5500)

    # base_name = ['.'.join(x.split('.')[:-1]) for x in image_file]
    # df = pd.DataFrame({
    #     'base_names': base_name,
    #     'file_name': image_file,
    #     'file_dir': [os.path.join(image_dir, x) for x in image_file],
    #     'autolabeling_dir': [os.path.join(sample_label, f'{x}_crop') for x in base_name],  # íƒ€ì¼ ë¼ë²¨ë§ ê²°ê³¼
    #     'img_dir': [os.path.join(sample_imgs, f'{x}_compare') for x in base_name]})  # ë¼ë²¨ë§ ë¹„êµ ì´ë¯¸ì§€ ê²°ê³¼
    
    # definition.rebuild_dir(sample_crop)
    # definition.cropping_image(df, sample_crop)  # ì´ë¯¸ì§€ ìë¥´ê¸°: 512*512

    # ENCODER = 'efficientnet-b2'
    # ENCODER_WEIGHTS = 'imagenet'
    # CLASSES = ['cell']
    # ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation
    # DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    # # create segmentation model with pretrained encoder
    # model = smp.UnetPlusPlus(
    #     encoder_name=ENCODER,
    #     encoder_weights=ENCODER_WEIGHTS,
    #     classes=len(CLASSES),
    #     activation=ACTIVATION,
    # )
    # preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)
    # # Create test dataset
    # test_dataset = definition.InferenceDataset(
    #     images_dir=image_dir,
    #     classes=CLASSES,
    #     preprocessing= definition.get_preprocessing(preprocessing_fn),
    # )
    
    # best_model = torch.load(os.path.join(ckpt_path,'{}_model2.pth'.format(dataset_name)), map_location=DEVICE)

    # test_dataloader = DataLoader(
    #     test_dataset, 
    #     batch_size=8, # í•œ ë²ˆì— í•˜ë‚˜ì˜ ì›ë³¸ ì´ë¯¸ì§€(ì˜ íƒ€ì¼ë“¤)ë¥¼ ì²˜ë¦¬
    #     shuffle=False, 
    #     num_workers=0,  # num_workers/ëŠ” ì‹œìŠ¤í…œì˜ CPU ì½”ì–´ ìˆ˜ë¥¼ í™œìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰
    #     # num_workers=os.cpu_count(), # ì‹œìŠ¤í…œì˜ CPU ì½”ì–´ ìˆ˜ í™œìš©
    #     collate_fn=definition.inference_collate_fn
    # )
    
    # definition.build_dir(sample_label)
    # definition.build_dir(sample_prediction)

    # @torch.no_grad() # ì¶”ë¡  ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
    # def inference_on_folder(model, dataloader, device, output_dir, inference_dir):
    #     model.eval().to(device)
    #     progress_bar = tqdm(dataloader, desc="Inference Progress")
        
    #     full_masks = {}
    #     num = 0
        
    #     for i, data in enumerate(progress_bar):
    #         tiles_batch, h_starts, w_starts, heights, widths, image_names = data
    #         #print(f"\n[{i+1}/{len(dataloader)}] ë°°ì¹˜ ì¶”ë¡  ì¤‘...")        
    #         tiles_batch = (tiles_batch).to(device)  
            
    #         # ëª¨ë¸ ì˜ˆì¸¡
    #         prediction = model(tiles_batch) # ì¶œë ¥: (batch_size, num_classes, H, W)
    #         predictions = prediction.cpu().numpy() 
            
    #         for j in range(len(image_names)):
    #             img_name = image_names[j]
    #             h_start = h_starts[j]
    #             w_start = w_starts[j]
    #             height = heights[j]
    #             width = widths[j]
    #             predicted_mask_tile = predictions[j]
    #             # í™œì„±í™” í•¨ìˆ˜ ì ìš© í›„ CPUë¡œ ì´ë™í•˜ê³  NumPy ë°°ì—´ë¡œ ë³€í™˜
    #             # sigmoid í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ [0, 1] ë²”ìœ„ì˜ í™•ë¥  ë§µì´ ì¶œë ¥ë©ë‹ˆë‹¤.
    #             # 'cell' í´ë˜ìŠ¤ í•˜ë‚˜ë§Œ ì˜ˆì¸¡í•˜ë¯€ë¡œ prediction.squeeze()ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    #             # thresholdë¥¼ ì ìš©í•˜ì—¬ ì´ì§„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜ (0.5 ì´ìƒì´ë©´ 1, ì•„ë‹ˆë©´ 0)
                
    #             # ë‹¨ì¼ í´ë˜ìŠ¤ ì´ì§„ ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ê²½ìš° (1, H, W) -> (H, W)
    #             if len(CLASSES) == 1:
    #                 predicted_mask_tile = predicted_mask_tile.squeeze(0) # (H, W)
    #                 predicted_mask_tile = (predicted_mask_tile > 0.5).astype(np.uint8) * 255 # ì´ì§„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜ (0 ë˜ëŠ” 255)
    #             else:
    #                 # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ê²½ìš° argmax ì‚¬ìš©
    #                 predicted_mask_tile = np.argmax(predicted_mask_tile, axis=0).astype(np.uint8) # (H, W)
    #                 # í´ë˜ìŠ¤ IDë¥¼ ì‹¤ì œ í”½ì…€ ê°’ìœ¼ë¡œ ë§¤í•‘í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: 0, 1, 2... ì— ë”°ë¼ ë‹¤ë¥¸ ìƒ‰ìƒ)
    #                 # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ 255ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    #                 predicted_mask_tile = predicted_mask_tile * (255 // (len(CLASSES) -1)) if len(CLASSES) > 1 else predicted_mask_tile * 255
    #             tile_path = os.path.join(inference_dir,f"{img_name}_crop", f"{num:05d}.png")
    #             cv2.imwrite(tile_path, predicted_mask_tile)     
                
    #             if definition.has_less_white_pixels(tile_path, 1000):
    #                 os.remove(tile_path)
    #                 continue
    #             num += 1

    #             # --- ì „ì²´ ë§ˆìŠ¤í¬ ì¬êµ¬ì„± ë¡œì§ ---
    #             # í˜„ì¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì „ì²´ ë§ˆìŠ¤í¬ê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    #             if img_name not in full_masks:
    #                 full_masks[img_name] = np.zeros((height, width), dtype=np.uint8)
                
    #             h_end = min(h_start + 512, height)
    #             w_end = min(w_start + 512, width)
                
    #             # ì¬êµ¬ì„±í•  ë§ˆìŠ¤í¬ì˜ ì‹¤ì œ ë†’ì´ì™€ ë„ˆë¹„
    #             actual_reconstruct_height = h_end - h_start
    #             actual_reconstruct_width = w_end - w_start
                
    #             # ì˜ˆì¸¡ëœ íƒ€ì¼ ë§ˆìŠ¤í¬ì—ì„œ ì›ë³¸ ì˜ì—­ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œ
    #             reconstructed_tile = predicted_mask_tile[:actual_reconstruct_height, :actual_reconstruct_width]
                
    #             # ì „ì²´ ë§ˆìŠ¤í¬ì— ì¬êµ¬ì„±
    #             full_masks[img_name][h_start:h_end, w_start:w_end] = reconstructed_tile
    #         # í˜„ì¬ ë°°ì¹˜ì˜ ì¶”ë¡  ì§„í–‰ ìƒí™© ì¶œë ¥
    #         #print(f"[{i+1}/{len(dataloader)}] ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ.")

    #     # ëª¨ë“  ë°°ì¹˜ê°€ ì²˜ë¦¬ëœ í›„, ìµœì¢… ë§ˆìŠ¤í¬ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    #     print("\nëª¨ë“  ì´ë¯¸ì§€ íƒ€ì¼ ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ğŸ’¾")
        
    #     for img_name, full_mask in full_masks.items():
    #         output_path = os.path.join(output_dir, f"{img_name}_mask.png")
    #         cv2.imwrite(output_path, full_mask)
    #         print(f"'{img_name}'ì˜ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ë¥¼ '{output_path}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. âœ…")

    # # ì¶”ë¡  ì‹¤í–‰
    # inference_on_folder(best_model, test_dataloader, DEVICE, sample_prediction, sample_label)
    

    # definition.build_dir(sample_prediction)
    count = len(os.listdir(sample_prediction))

    print(f"{count}/{sample_prediction}")
